{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在SD21上测试PAN攻击"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.dataset_name = 'VGGFace2-clean'\n",
    "        self.instance_name = '0'\n",
    "        self.advance_steps = 2\n",
    "        self.target_weight = 1\n",
    "        self.device = 2\n",
    "        self.exp_name = 'release-MetaCloak-advance_steps-2-total_trail_num-1-unroll_steps-1-interval-2-total_train_steps-10-SD21base-robust-gauK-7'\n",
    "        self.exp_hyper = 'dataset-VGGFace2-clean-r-11-model-SD21base-gen_prompt-sks'\n",
    "        self.pretrained_model_name_or_path = '/data/home/yekai/github/mypro/MetaCloak/SD/stable-diffusion-2-1-base'\n",
    "        self.revision = None\n",
    "        self.tokenizer_name = None\n",
    "        self.class_data_dir = '/data/home/yekai/github/mypro/MetaCloak/prior-data/SD21base/class-person'\n",
    "        self.instance_prompt = 'a photo of sks person'\n",
    "        self.class_prompt = 'a photo of person'\n",
    "        self.with_prior_preservation = True\n",
    "        self.prior_loss_weight = 1.0\n",
    "        self.num_class_images = 200\n",
    "        self.output_dir = '/data/home/yekai/github/mypro/MetaCloak/exp_data/gen_output/release-MetaCloak-advance_steps-2-total_trail_num-1-unroll_steps-1-interval-2-total_train_steps-10-SD21base-robust-gauK-7/dataset-VGGFace2-clean-r-11-model-SD21base-gen_prompt-sks/0'\n",
    "        self.seed = 0\n",
    "        self.resolution = 512\n",
    "        self.center_crop = True\n",
    "        self.train_text_encoder = True\n",
    "        self.train_batch_size = 1\n",
    "        self.sample_batch_size = 8\n",
    "        self.max_train_steps = 20\n",
    "        self.checkpointing_iterations = 10\n",
    "        self.learning_rate = 5e-07\n",
    "        self.logging_dir = 'logs'\n",
    "        self.allow_tf32 = False\n",
    "        self.report_to = 'wandb'\n",
    "        self.mixed_precision = 'fp16'\n",
    "        self.enable_xformers_memory_efficient_attention = True\n",
    "        self.wandb_entity_name = 'vkeilo'\n",
    "        self.wandb_run_name = 'MAT-PAN-10-2-1-1-x1x1-radius11-noSGLD-robust0-10-0.01-0.5-k=2-useS-last-1728469324'\n",
    "        self.wandb_project_name = 'metacloak_PAN'\n",
    "        self.transform_hflip = True\n",
    "        self.instance_data_dir_for_train = '/data/home/yekai/github/mypro/MetaCloak/dataset/VGGFace2-clean/0/set_A'\n",
    "        self.instance_data_dir_for_adversarial = '/data/home/yekai/github/mypro/MetaCloak/dataset/VGGFace2-clean/0/set_B'\n",
    "        self.defense_pgd_ascending = True\n",
    "        self.defense_pgd_radius = 11.0\n",
    "        self.defense_pgd_step_size = 1.1\n",
    "        self.defense_pgd_step_num = 1\n",
    "        self.defense_pgd_random_start = False\n",
    "        self.attack_pgd_radius = 11.0\n",
    "        self.attack_pgd_step_size = 0.3\n",
    "        self.attack_pgd_step_num = 6\n",
    "        self.attack_pgd_ascending = False\n",
    "        self.attack_pgd_random_start = False\n",
    "        self.target_image_path = None\n",
    "        self.gau_kernel_size = 7\n",
    "        self.defense_sample_num = 1\n",
    "        self.rot_degree = 5\n",
    "        self.transform_rot = False\n",
    "        self.transform_gau = True\n",
    "        self.original_flow = False\n",
    "        self.total_trail_num = 1\n",
    "        self.unroll_steps = 1\n",
    "        self.interval = 2\n",
    "        self.total_train_steps = 10\n",
    "        self.beta_s = 0.3\n",
    "        self.beta_p = 0.3\n",
    "        self.sampling_times_theta = 1\n",
    "        self.sampling_times_delta = 1\n",
    "        self.sampling_step_theta = 1e-05\n",
    "        self.sampling_step_delta = 1e-05\n",
    "        self.sampling_noise_ratio = 0.05\n",
    "        self.attack_mode = 'pan'\n",
    "        self.pan_lambda_D = 0.01\n",
    "        self.pan_lambda_S = 10.0\n",
    "        self.pan_omiga = 0.5\n",
    "        self.pan_k = 2\n",
    "        self.pan_mode = 'S'\n",
    "        self.init_model_state_pool_pth_path = '/data/home/yekai/github/mypro/MetaCloak/robust_facecloak/attacks/algs/tmpdata/init_model_state_pool_sd2-1.pth'\n",
    "        self.pan_use_val = 'last'\n",
    "        self.model_select_mode = 'order'\n",
    "        self.total_gan_step = 0\n",
    "        self.SGLD_method = 'noSGLD'\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/yekai/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-10-24 10:26:17.679637: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-24 10:26:17.679711: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-24 10:26:17.681329: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-24 10:26:17.688819: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-24 10:26:18.381253: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/data/home/yekai/github/mypro')\n",
    "sys.path.append('/data/home/yekai/github/mypro/MetaCloak')\n",
    "\n",
    "import random\n",
    "import wandb\n",
    "import argparse\n",
    "import copy\n",
    "import hashlib\n",
    "import itertools\n",
    "import logging\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from pathlib import Path\n",
    "import datasets\n",
    "import diffusers\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed\n",
    "from diffusers import AutoencoderKL, DDPMScheduler, DiffusionPipeline, UNet2DConditionModel\n",
    "from diffusers.utils.import_utils import is_xformers_available\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, PretrainedConfig\n",
    "from robust_facecloak.model.db_train import  DreamBoothDatasetFromTensor\n",
    "from robust_facecloak.model.db_train import import_model_class_from_model_name_or_path\n",
    "from robust_facecloak.generic.data_utils import PromptDataset, load_data\n",
    "from robust_facecloak.generic.share_args import share_parse_args\n",
    "# vkeilo add it\n",
    "import utils\n",
    "import GPUtil\n",
    "import time\n",
    "import pickle\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# vkeilo add\n",
    "device_g = torch.device(\"cuda\")\n",
    "# 针对模型的unet和文本编码器进行的训练\n",
    "def train_few_step(\n",
    "    args,\n",
    "    models,\n",
    "    tokenizer,\n",
    "    noise_scheduler,\n",
    "    vae,\n",
    "    data_tensor: torch.Tensor,\n",
    "    num_steps=20,\n",
    "    step_wise_save=False,\n",
    "    save_step=100, \n",
    "    retain_graph=False,\n",
    "    dpcopy = True,\n",
    "    task_loss_name = None,\n",
    "    loss_return = False,\n",
    "):\n",
    "    # Load the tokenizer\n",
    "    # vkeilo remove deepcopy\n",
    "    if dpcopy:\n",
    "        unet, text_encoder = copy.deepcopy(models[0]), copy.deepcopy(models[1])\n",
    "    else:\n",
    "        unet, text_encoder = models[0], models[1]\n",
    "    # unet, text_encoder = models[0], models[1]\n",
    "    # 绑定unet和文本编码器的参数，共同优化\n",
    "    params_to_optimize = itertools.chain(unet.parameters(), text_encoder.parameters())\n",
    "\n",
    "    # 设置优化器，优化目标为unet参数和文本编码器参数\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        params_to_optimize,\n",
    "        lr=args.learning_rate,\n",
    "        betas=(0.9, 0.999),\n",
    "        weight_decay=1e-2,\n",
    "        eps=1e-08,\n",
    "    )\n",
    "\n",
    "    train_dataset = DreamBoothDatasetFromTensor(\n",
    "        data_tensor,\n",
    "        # A photo of sks person\n",
    "        args.instance_prompt,\n",
    "        tokenizer,\n",
    "        args.class_data_dir,\n",
    "        args.class_prompt,\n",
    "        args.resolution,\n",
    "        args.center_crop,\n",
    "    )\n",
    "\n",
    "    weight_dtype = torch.bfloat16\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    # 将关键模型移动到对应设备\n",
    "    vae.to(device, dtype=weight_dtype)\n",
    "    text_encoder.to(device, dtype=weight_dtype)\n",
    "    unet.to(device, dtype=weight_dtype)\n",
    "\n",
    "    \n",
    "    step2modelstate={}\n",
    "        \n",
    "    pbar = tqdm(total=num_steps, desc=\"training\")\n",
    "    for step in range(num_steps):\n",
    "        # 根据设置选择是否保存训练中间过程参数\n",
    "        if step_wise_save and ((step+1) % save_step == 0 or step == 0):\n",
    "            # make sure the model state dict is put to cpu\n",
    "            step2modelstate[step] = {\n",
    "                \"unet\": copy.deepcopy(unet.cpu().state_dict()),\n",
    "                \"text_encoder\": copy.deepcopy(text_encoder.cpu().state_dict()),\n",
    "            }\n",
    "            # move the model back to gpu\n",
    "            unet.to(device, dtype=weight_dtype); text_encoder.to(device, dtype=weight_dtype)\n",
    "            \n",
    "        pbar.update(1)\n",
    "        # 训练模式\n",
    "        unet.train()\n",
    "        text_encoder.train()\n",
    "        # 循环从训练数据集中取一个样本\n",
    "        step_data = train_dataset[step % len(train_dataset)]\n",
    "        # 将样本中的类别图片和实例图片整合并移动到设备上\n",
    "        pixel_values = torch.stack([step_data[\"instance_images\"], step_data[\"class_images\"]]).to(\n",
    "            device, dtype=weight_dtype\n",
    "        )\n",
    "        # 将样本中的类别提示词和实例提示词整合并移动到设备上\n",
    "        input_ids = torch.cat([step_data[\"instance_prompt_ids\"], step_data[\"class_prompt_ids\"]], dim=0).to(device)\n",
    "        # 使用VAE对图像进行编码，并对潜在表示进行后处理\n",
    "        latents = vae.encode(pixel_values).latent_dist.sample()\n",
    "        latents = latents * vae.config.scaling_factor\n",
    "        # print(f'latents shape: {latents.shape}')\n",
    "        # Sample noise that we'll add to the latents\n",
    "        # 向图片编码向量（潜在空间向量表示）添加随机噪声\n",
    "        noise = torch.randn_like(latents)\n",
    "        # batch_size\n",
    "        bsz = latents.shape[0]\n",
    "        # Sample a random timestep for each image\n",
    "        # 为每个图片生成一个随机step\n",
    "        timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device)\n",
    "        timesteps = timesteps.long()\n",
    "\n",
    "        # Add noise to the latents according to the noise magnitude at each timestep\n",
    "        # (this is the forward diffusion process)\n",
    "        # 前向过程，得到前向扩散特定时间步后的图片的潜在空间向量\n",
    "        noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "\n",
    "        # Get the text embedding for conditioning\n",
    "        # 文本编码向量作为条件信息\n",
    "        encoder_hidden_states = text_encoder(input_ids)[0]\n",
    "        \n",
    "        # Predict the noise residual\n",
    "        # 模型基于当前的噪声潜在表示（noisy_latents）、时间步（timesteps）和文本条件（encoder_hidden_states），预测噪声残差\n",
    "        # print(f'noisy_latents shape: {noisy_latents.shape}')\n",
    "        model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
    "        # print('model_pred shape', model_pred.shape)\n",
    "        # Get the target for loss depending on the prediction type\n",
    "        # 预测的可以是噪声，也可以是变化速度\n",
    "        if noise_scheduler.config.prediction_type == \"epsilon\":\n",
    "            target = noise\n",
    "        elif noise_scheduler.config.prediction_type == \"v_prediction\":\n",
    "            target = noise_scheduler.get_velocity(latents, noise, timesteps)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown prediction type {noise_scheduler.config.prediction_type}\")\n",
    "\n",
    "        if args.with_prior_preservation:\n",
    "            # 再次分为一半一半，对应之前的stack操作\n",
    "            model_pred, model_pred_prior = torch.chunk(model_pred, 2, dim=0)\n",
    "            target, target_prior = torch.chunk(target, 2, dim=0)\n",
    "\n",
    "            # Compute instance loss\n",
    "            instance_loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\")\n",
    "\n",
    "            # Compute prior loss  确保在原来类别上的生成能力不丢失\n",
    "            prior_loss = F.mse_loss(model_pred_prior.float(), target_prior.float(), reduction=\"mean\")\n",
    "\n",
    "            # Add the prior loss to the instance loss.\n",
    "            loss = instance_loss + args.prior_loss_weight * prior_loss\n",
    "\n",
    "        else:\n",
    "            # 不使用先验保留损失\n",
    "            loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\")\n",
    "        # 反向传播\n",
    "        loss.backward(retain_graph=retain_graph)\n",
    "        # 梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(params_to_optimize, 1.0, error_if_nonfinite=True)\n",
    "        # 参数优化\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    pbar.close()\n",
    "    # 返回训练的参数数据\n",
    "    if not loss_return:\n",
    "        if step_wise_save:\n",
    "            return [unet, text_encoder], step2modelstate\n",
    "        else:     \n",
    "            return [unet, text_encoder]\n",
    "    else:\n",
    "        if step_wise_save:\n",
    "            return [unet, text_encoder], step2modelstate, loss.item()\n",
    "        else:     \n",
    "            return [unet, text_encoder], loss.item()\n",
    "\n",
    "# 主要模型的加载\n",
    "def load_model(args, model_path):\n",
    "    print(f'out {model_path}')\n",
    "    # import correct text encoder class\n",
    "    text_encoder_cls = import_model_class_from_model_name_or_path(model_path, args.revision)\n",
    "\n",
    "    # Load scheduler and models\n",
    "    # 文本编码器加载\n",
    "    text_encoder = text_encoder_cls.from_pretrained(\n",
    "        model_path,\n",
    "        subfolder=\"text_encoder\",\n",
    "        revision=args.revision,\n",
    "    )\n",
    "    # unet加载\n",
    "    unet = UNet2DConditionModel.from_pretrained(model_path, subfolder=\"unet\", revision=args.revision)\n",
    "\n",
    "    # vkeilo add it\n",
    "    # text_encoder = text_encoder.bfloat16()\n",
    "    # unet = unet.bfloat16()\n",
    "\n",
    "    # tokenizer加载\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_path,\n",
    "        subfolder=\"tokenizer\",\n",
    "        revision=args.revision,\n",
    "        use_fast=False,\n",
    "    )\n",
    "    # 使用DDPM同款调度器\n",
    "    noise_scheduler = DDPMScheduler.from_pretrained(model_path, subfolder=\"scheduler\")\n",
    "    # 加载预训练的vae，vae不需要更新参数\n",
    "    vae = AutoencoderKL.from_pretrained(model_path, subfolder=\"vae\", revision=args.revision)\n",
    "\n",
    "    vae.requires_grad_(False)\n",
    "\n",
    "    # 甚至可以不更新文本编码器的参数\n",
    "    if not args.train_text_encoder:\n",
    "        text_encoder.requires_grad_(False)\n",
    "\n",
    "    if args.enable_xformers_memory_efficient_attention:\n",
    "        print(\"You selected to used efficient xformers\")\n",
    "        print(\"Make sure to install the following packages before continue\")\n",
    "        print(\"pip install triton==2.0.0.dev20221031\")\n",
    "        print(\"pip install pip install xformers==0.0.17.dev461\")\n",
    "\n",
    "        unet.enable_xformers_memory_efficient_attention()\n",
    "    # 返回5个关键模型\n",
    "    return text_encoder, unet, tokenizer, noise_scheduler, vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_pixel_change(original_img, noisy_img):\n",
    "    diff = torch.abs(original_img - noisy_img)\n",
    "\n",
    "    # Find the maximum pixel difference\n",
    "    max_change = torch.max(diff)\n",
    "\n",
    "    return max_change.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "wait here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait here\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: wait here"
     ]
    }
   ],
   "source": [
    "raise ValueError(\"wait here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/23/2024 17:08:34 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args model path:/data/home/yekai/github/mypro/MetaCloak/SD/stable-diffusion-2-1-base\n",
      "out /data/home/yekai/github/mypro/MetaCloak/SD/stable-diffusion-2-1-base\n",
      "model_path:/data/home/yekai/github/mypro/MetaCloak/SD/stable-diffusion-2-1-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'conv_out_kernel', 'class_embed_type', 'mid_block_type', 'upcast_attention', 'timestep_post_act', 'projection_class_embeddings_input_dim', 'time_cond_proj_dim', 'time_embedding_type', 'resnet_time_scale_shift', 'conv_in_kernel'} was not found in config. Values will be initialized to default values.\n",
      "{'clip_sample_range', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You selected to used efficient xformers\n",
      "Make sure to install the following packages before continue\n",
      "pip install triton==2.0.0.dev20221031\n",
      "pip install pip install xformers==0.0.17.dev461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing models:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 use trained pth:/data/home/yekai/github/mypro/MetaCloak/robust_facecloak/attacks/algs/tmpdata/init_model_state_pool_sd2-1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing models: 100%|██████████| 1/1 [00:16<00:00, 16.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 199, 399, 599, 799, 999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "meta poison with model ensemble:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avalaible model num: 1,available steps: [0, 199, 399, 599, 799, 999],total train step :10\n",
      "using model 0\n",
      "start 1 times of defense optimization in step-0 model\n",
      "start 1 times of delta sampling \n",
      "sample delta 0/1 times\n",
      "epoch: 0, loss_S: -0.1689, loss_D: -0.0488\n",
      "epoch: 1, loss_S: 2.3708, loss_D: -0.0786\n",
      "epoch: 2, loss_S: 9.9516, loss_D: -0.0539\n",
      "epoch: 3, loss_S: 22.4449, loss_D: -0.0496\n",
      "epoch: 4, loss_S: 39.8992, loss_D: -0.0325\n",
      "epoch: 5, loss_S: 62.3581, loss_D: -0.1104\n",
      "max pixel change:2.100006103515625\n",
      "sample theta 0/1 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2/2 [00:00<00:00,  3.80it/s]\n",
      "meta poison with model ensemble:  17%|█▋        | 1/6 [00:11<00:58, 11.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1 times of defense optimization in step-199 model\n",
      "start 1 times of delta sampling \n",
      "sample delta 0/1 times\n",
      "epoch: 0, loss_S: 39.9578, loss_D: -0.0431\n",
      "epoch: 1, loss_S: 62.4197, loss_D: -0.0659\n",
      "epoch: 2, loss_S: 89.8181, loss_D: -0.2679\n",
      "epoch: 3, loss_S: 122.3048, loss_D: -0.0666\n",
      "epoch: 4, loss_S: 159.9632, loss_D: -0.0260\n",
      "epoch: 5, loss_S: 201.9445, loss_D: -0.0191\n",
      "max pixel change:4.1300048828125\n",
      "sample theta 0/1 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2/2 [00:00<00:00,  3.95it/s]\n",
      "meta poison with model ensemble:  33%|███▎      | 2/6 [00:21<00:42, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1 times of defense optimization in step-399 model\n",
      "start 1 times of delta sampling \n",
      "sample delta 0/1 times\n",
      "epoch: 0, loss_S: 159.9458, loss_D: -0.0333\n",
      "epoch: 1, loss_S: 201.9585, loss_D: -0.0202\n",
      "epoch: 2, loss_S: 249.9581, loss_D: -0.0509\n",
      "epoch: 3, loss_S: 301.9663, loss_D: -0.1973\n",
      "epoch: 4, loss_S: 359.9064, loss_D: -0.1347\n",
      "epoch: 5, loss_S: 421.9865, loss_D: -0.0934\n",
      "max pixel change:6.139007568359375\n",
      "sample theta 0/1 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2/2 [00:00<00:00,  3.96it/s]\n",
      "meta poison with model ensemble:  50%|█████     | 3/6 [00:31<00:31, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1 times of defense optimization in step-599 model\n",
      "start 1 times of delta sampling \n",
      "sample delta 0/1 times\n",
      "epoch: 0, loss_S: 359.9171, loss_D: -0.0761\n",
      "epoch: 1, loss_S: 421.7921, loss_D: -0.0661\n",
      "epoch: 2, loss_S: 489.9617, loss_D: -0.0405\n",
      "epoch: 3, loss_S: 563.8845, loss_D: -0.0895\n",
      "epoch: 4, loss_S: 639.9797, loss_D: -0.0313\n",
      "epoch: 5, loss_S: 719.9034, loss_D: -0.0294\n",
      "max pixel change:8.141708374023438\n",
      "sample theta 0/1 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2/2 [00:00<00:00,  3.95it/s]\n",
      "meta poison with model ensemble:  67%|██████▋   | 4/6 [00:41<00:20, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1 times of defense optimization in step-799 model\n",
      "start 1 times of delta sampling \n",
      "sample delta 0/1 times\n",
      "epoch: 0, loss_S: 639.8359, loss_D: -0.0214\n",
      "epoch: 1, loss_S: 719.9029, loss_D: -0.0267\n",
      "epoch: 2, loss_S: 807.9678, loss_D: -0.0471\n",
      "epoch: 3, loss_S: 899.9095, loss_D: -0.2615\n",
      "epoch: 4, loss_S: 999.9913, loss_D: -0.0461\n",
      "epoch: 5, loss_S: 1103.9666, loss_D: -0.0609\n",
      "max pixel change:10.14251708984375\n",
      "sample theta 0/1 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2/2 [00:00<00:00,  3.96it/s]\n",
      "meta poison with model ensemble:  83%|████████▎ | 5/6 [00:51<00:10, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1 times of defense optimization in step-999 model\n",
      "start 1 times of delta sampling \n",
      "sample delta 0/1 times\n",
      "epoch: 0, loss_S: 999.8782, loss_D: -0.0215\n",
      "epoch: 1, loss_S: 1103.9403, loss_D: -0.0939\n",
      "epoch: 2, loss_S: 1207.9139, loss_D: -0.0819\n",
      "epoch: 3, loss_S: 1207.7570, loss_D: -0.0832\n",
      "epoch: 4, loss_S: 1207.8892, loss_D: -0.1872\n",
      "epoch: 5, loss_S: 1207.9585, loss_D: -0.2219\n",
      "max pixel change:10.742759704589844\n",
      "sample theta 0/1 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2/2 [00:00<00:00,  3.91it/s]\n",
      "meta poison with model ensemble: 100%|██████████| 6/6 [01:02<00:00, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max pixel change:10.742759704589844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 确保SGLD方法参数合法\n",
    "assert args.SGLD_method in [\"allSGLD\", \"thetaSGLD\", \"deltaSGLD\" ,\"noSGLD\"]\n",
    "# 指定日志目录\n",
    "logging_dir = Path(args.output_dir, args.logging_dir)\n",
    "# Hugging Face加速器，指定混合精度训练模式和记录方式，默认为wandb\n",
    "accelerator = Accelerator(\n",
    "    mixed_precision=args.mixed_precision,\n",
    "    log_with=args.report_to,\n",
    "    # logging_dir=logging_dir,\n",
    ")\n",
    "\n",
    "# 初始化日志记录器，指定格式和日志级别\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "# 记录加速器信息\n",
    "logger.info(accelerator.state, main_process_only=False)\n",
    "# 只在主进程上尽可能详细地记录日志\n",
    "if accelerator.is_local_main_process:\n",
    "    datasets.utils.logging.set_verbosity_warning()\n",
    "    transformers.utils.logging.set_verbosity_warning()\n",
    "    diffusers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    datasets.utils.logging.set_verbosity_error()\n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "    diffusers.utils.logging.set_verbosity_error()\n",
    "# 设置随机种子\n",
    "if args.seed is not None:\n",
    "    set_seed(args.seed)\n",
    "\n",
    "# Generate class images if prior preservation is enabled.\n",
    "# 如果启用了先验保留，则先生成类图像，保存在变量cur_class_images中\n",
    "if args.with_prior_preservation:\n",
    "    # 检查并创建一个用于存储类别图像的目录，并统计当前目录中已经存在的类别图像数量\n",
    "    class_images_dir = Path(args.class_data_dir)\n",
    "    if not class_images_dir.exists():\n",
    "        class_images_dir.mkdir(parents=True)\n",
    "    cur_class_images = len(list(class_images_dir.iterdir()))\n",
    "    # 如果当前类别图像数量小于所需数量，则生成新的类别图像\n",
    "    if cur_class_images < args.num_class_images:\n",
    "        torch_dtype = torch.float16 if accelerator.device.type == \"cuda\" else torch.float32\n",
    "        if args.mixed_precision == \"fp32\":\n",
    "            torch_dtype = torch.float32\n",
    "        elif args.mixed_precision == \"fp16\":\n",
    "            torch_dtype = torch.float16\n",
    "        elif args.mixed_precision == \"bf16\":\n",
    "            torch_dtype = torch.bfloat16\n",
    "        # 此处的pipline是用来根据类别提示生成类别图像的模型\n",
    "        pipeline = DiffusionPipeline.from_pretrained(\n",
    "            list(args.pretrained_model_name_or_path.split(\",\"))[-1], \n",
    "            torch_dtype=torch_dtype,\n",
    "            safety_checker=None,\n",
    "            revision=args.revision,\n",
    "        )\n",
    "        # 生成类别图像时，不显示进度条\n",
    "        pipeline.set_progress_bar_config(disable=True)\n",
    "        # 计算还需要生成的类别图像数量，num_class_images默认为200\n",
    "        num_new_images = args.num_class_images - cur_class_images\n",
    "        logger.info(f\"Number of class images to sample: {num_new_images}.\")\n",
    "        # 类别生成的提示词数据（其实都是 a photo of a person，因为在隐私保护中，扩散模型的的先验能力就是在人像类别上的生成能力）\n",
    "        sample_dataset = PromptDataset(args.class_prompt, num_new_images)\n",
    "        # sample_batch_size默认为4\n",
    "        sample_dataloader = torch.utils.data.DataLoader(sample_dataset, batch_size=args.sample_batch_size)\n",
    "        # 将数据集使用accelerator进行预处理（就是设置为使用混合精度和wandb记录）\n",
    "        sample_dataloader = accelerator.prepare(sample_dataloader)\n",
    "        # 将模型移动到accelerator.device上（accelerator） 会自动选择\n",
    "        pipeline.to(accelerator.device)\n",
    "\n",
    "        # 每批4个提示词，生成4个类别图像（一样的提示词）\n",
    "        for example in tqdm(\n",
    "            sample_dataloader,\n",
    "            desc=\"Generating class images\",\n",
    "            disable=not accelerator.is_local_main_process,\n",
    "        ):\n",
    "            images = pipeline(example[\"prompt\"]).images\n",
    "\n",
    "            for i, image in enumerate(images):\n",
    "                # 使用哈希值为图像文件名，并保存\n",
    "                hash_image = hashlib.sha1(image.tobytes()).hexdigest()\n",
    "                image_filename = class_images_dir / f\"{example['index'][i] + cur_class_images}-{hash_image}.jpg\"\n",
    "                image.save(image_filename)\n",
    "        # 删除模型，释放显存\n",
    "        del pipeline\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# 判断是否启用tf32加速\n",
    "if args.allow_tf32:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# 加载干净数据\n",
    "clean_data = load_data(\n",
    "    args.instance_data_dir_for_train,\n",
    "    # size=args.resolution,\n",
    "    # center_crop=args.center_crop,\n",
    ")\n",
    "\n",
    "# 加载原始扰动数据\n",
    "perturbed_data = load_data(\n",
    "    args.instance_data_dir_for_adversarial,\n",
    "    # size=args.resolution,\n",
    "    # center_crop=args.center_crop,\n",
    ")\n",
    "\n",
    "# original_data当前为原始扰动数据\n",
    "original_data= copy.deepcopy(perturbed_data)\n",
    "    \n",
    "import torchvision\n",
    "# 定义训练和测试时的数据增强（图像处理）\n",
    "train_aug = [\n",
    "        # 双线性插值到512x512\n",
    "        transforms.Resize(args.resolution, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        # 裁剪\n",
    "        transforms.CenterCrop(args.resolution) if args.center_crop else transforms.RandomCrop(args.resolution),\n",
    "]\n",
    "# 图像随机旋转\n",
    "rotater = torchvision.transforms.RandomRotation(degrees=(0, args.rot_degree))\n",
    "# 高斯模糊\n",
    "gau_filter = transforms.GaussianBlur(kernel_size=args.gau_kernel_size,)\n",
    "# 制定防御对抗样本变换策略\n",
    "defense_transform = [\n",
    "]\n",
    "if args.transform_hflip:\n",
    "    defense_transform = defense_transform + [transforms.RandomHorizontalFlip(p=0.5)]\n",
    "if args.transform_rot:\n",
    "    defense_transform = defense_transform + [rotater]\n",
    "if args.transform_gau:\n",
    "    defense_transform = [gau_filter] + defense_transform\n",
    "\n",
    "# 标准化均值和标准差\n",
    "tensorize_and_normalize = [\n",
    "    transforms.Normalize([0.5*255]*3,[0.5*255]*3),\n",
    "]\n",
    "\n",
    "# 将所有变换组合起来，整合为一个Compose对象\n",
    "all_trans = train_aug + defense_transform + tensorize_and_normalize\n",
    "all_trans = transforms.Compose(all_trans)\n",
    "\n",
    "\n",
    "from robust_facecloak.attacks.worker.robust_pgd_worker_vk import RobustPGDAttacker\n",
    "from MetaCloak.robust_facecloak.attacks.worker.pgd_worker import PGDAttacker\n",
    "from MetaCloak.robust_facecloak.attacks.worker.pan_worker import PANAttacker\n",
    "# 构建攻击者和防御者，攻击者使用PGD算法\n",
    "# attacker = PGDAttacker(\n",
    "#     radius=args.attack_pgd_radius, \n",
    "#     steps=args.attack_pgd_step_num, \n",
    "#     step_size=args.attack_pgd_step_size,\n",
    "#     random_start=args.attack_pgd_random_start,\n",
    "#     ascending=args.attack_pgd_ascending,\n",
    "#     args=args, \n",
    "#     x_range=[-1, 1],\n",
    "# )\n",
    "# defender = RobustPGDAttacker(\n",
    "#     radius=args.defense_pgd_radius,\n",
    "#     steps=args.defense_pgd_step_num, # 6\n",
    "#     step_size=args.defense_pgd_step_size,\n",
    "#     random_start=args.defense_pgd_random_start,\n",
    "#     ascending=args.defense_pgd_ascending,\n",
    "#     args=args,\n",
    "#     attacker=attacker, \n",
    "#     trans=all_trans,\n",
    "#     sample_num=args.defense_sample_num,\n",
    "#     x_range=[0, 255],\n",
    "# )\n",
    "assert args.attack_mode in ['pgd','pan']\n",
    "if args.attack_mode == 'pgd':\n",
    "    attacker = PGDAttacker(\n",
    "        radius=args.attack_pgd_radius, \n",
    "        steps=args.attack_pgd_step_num, \n",
    "        step_size=args.attack_pgd_step_size,\n",
    "        random_start=args.attack_pgd_random_start,\n",
    "        ascending=args.attack_pgd_ascending,\n",
    "        args=args, \n",
    "        x_range=[-1, 1],\n",
    "    )\n",
    "    defender = RobustPGDAttacker(\n",
    "        radius=args.defense_pgd_radius,\n",
    "        steps=args.defense_pgd_step_num, # 6\n",
    "        step_size=args.defense_pgd_step_size,\n",
    "        random_start=args.defense_pgd_random_start,\n",
    "        ascending=args.defense_pgd_ascending,\n",
    "        args=args,\n",
    "        attacker=attacker, \n",
    "        trans=all_trans,\n",
    "        sample_num=args.defense_sample_num,\n",
    "        x_range=[0, 255],\n",
    "        # vkeilo add it\n",
    "        # step_sample_num=args.sampling_times_delta\n",
    "    )\n",
    "else:\n",
    "    attacker = PANAttacker(\n",
    "        radius=args.attack_pgd_radius,\n",
    "        steps=args.attack_pgd_step_num,\n",
    "        step_size=args.attack_pgd_step_size,\n",
    "        # ascending=args.defense_pgd_ascending,\n",
    "        args=args,\n",
    "        # trans=all_trans,\n",
    "        # sample_num=args.defense_sample_num,\n",
    "        x_range=[0, 255],\n",
    "        lambda_D = args.pan_lambda_D,\n",
    "        lambda_S = args.pan_lambda_S,\n",
    "        k = args.pan_k,\n",
    "        mode = args.pan_mode,\n",
    "        use_val = args.pan_use_val,\n",
    "    )\n",
    "    attacker.weight_dtype = torch.bfloat16\n",
    "\n",
    "# 模型加载，本次实验只有一个\n",
    "print(f'args model path:{args.pretrained_model_name_or_path}')\n",
    "model_paths = list(args.pretrained_model_name_or_path.split(\",\"))\n",
    "num_models = len(model_paths)\n",
    "\n",
    "MODEL_BANKS = [load_model(args, path) for path in model_paths]\n",
    "\n",
    "# 提取模型的文本编码器和UNet的状态字典\n",
    "MODEL_STATEDICTS = [\n",
    "    {\n",
    "        \"text_encoder\": MODEL_BANKS[i][0].state_dict(),\n",
    "        \"unet\": MODEL_BANKS[i][1].state_dict(),\n",
    "    }\n",
    "    for i in range(num_models)\n",
    "]\n",
    "# 此函数将保存经过扰动处理的图像数据到noise-ckpt/{id_stamp}目录中，id_stamp在此次实验中为迭代次数\n",
    "def save_image(perturbed_data, id_stamp):\n",
    "    save_folder = f\"{args.output_dir}/noise-ckpt/{id_stamp}\"\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    noised_imgs = perturbed_data.detach()\n",
    "    img_names = [\n",
    "        str(instance_path).split(\"/\")[-1]\n",
    "        for instance_path in list(Path(args.instance_data_dir_for_adversarial).iterdir())\n",
    "    ]\n",
    "    for img_pixel, img_name in zip(noised_imgs, img_names):\n",
    "        save_path = os.path.join(save_folder, f\"noisy_{img_name}\")\n",
    "        Image.fromarray(\n",
    "            img_pixel.float().detach().cpu().permute(1, 2, 0).numpy().squeeze().astype(np.uint8)\n",
    "        ).save(save_path)\n",
    "\n",
    "\n",
    "init_model_state_pool = {}\n",
    "pbar = tqdm(total=num_models, desc=\"initializing models\")\n",
    "# split sub-models\n",
    "# 对于每一个模型，都进行一次训练\n",
    "for j in range(num_models):\n",
    "    init_model_state_pool[j] = {}\n",
    "    # 提取关键模块\n",
    "    text_encoder, unet, tokenizer, noise_scheduler, vae = MODEL_BANKS[j]\n",
    "    \n",
    "    # 加载unet和text_encoder的模型参数\n",
    "    unet.load_state_dict(MODEL_STATEDICTS[j][\"unet\"])\n",
    "    text_encoder.load_state_dict(MODEL_STATEDICTS[j][\"text_encoder\"])\n",
    "    # 打包unet和text_encoder\n",
    "    f_ori = [unet, text_encoder]\n",
    "    # 得到训练total_train_steps步之后的unet, text_encoder参数以及中间状态参数\n",
    "    # print('start train few 702')\n",
    "    if args.init_model_state_pool_pth_path is None:\n",
    "        f_ori, step2state_dict = train_few_step(\n",
    "                args,\n",
    "                f_ori,\n",
    "                tokenizer,\n",
    "                noise_scheduler,\n",
    "                vae,\n",
    "                perturbed_data.float(),\n",
    "                args.total_train_steps,\n",
    "                step_wise_save=True,\n",
    "                save_step=args.interval,\n",
    "                task_loss_name=\"ori_model_train_loss\",\n",
    "        )  \n",
    "        # init_model_state_pool就来保存训练中间状态参数\n",
    "        init_model_state_pool[j] = step2state_dict\n",
    "    else:\n",
    "        pre_trained_pth_path = args.init_model_state_pool_pth_path.split(',')[j]\n",
    "        print(f'model {j} use trained pth:{pre_trained_pth_path}')\n",
    "        with open(pre_trained_pth_path, 'rb') as f:\n",
    "            model_pth_dict = pickle.load(f)\n",
    "            init_model_state_pool[j] = model_pth_dict[0]\n",
    "    # 释放占用的资源\n",
    "    del f_ori, unet, text_encoder, tokenizer, noise_scheduler, vae\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "# 提取保存的中间状态的step数据（1000，2000，3000.....）        \n",
    "steps_list = list(init_model_state_pool[0].keys())\n",
    "print(steps_list)\n",
    "# 进度条，总train_few_step调用的次数*模型数量1*\n",
    "pbar = tqdm(total=args.total_trail_num * num_models * (args.interval // args.advance_steps) * len(steps_list), desc=\"meta poison with model ensemble\")\n",
    "\n",
    "if args.total_gan_step == 0:\n",
    "    total_gan_step = args.total_trail_num * num_models * (args.interval // args.advance_steps) * len(steps_list)\n",
    "else:\n",
    "    total_gan_step = args.total_gan_step\n",
    "cnt=0\n",
    "# vkeilo add it  确定噪声强度\n",
    "theta_noise_epsion = args.sampling_step_theta * args.sampling_noise_ratio\n",
    "delta_noise_epsion = args.sampling_step_delta * args.sampling_noise_ratio\n",
    "\n",
    "def select_target_model(loss_log):\n",
    "    # 选择loss最小的模型\n",
    "    loss_mean_list = []\n",
    "    for model_loss in loss_log:\n",
    "        for steps,loss_list in model_loss.items():\n",
    "            loss_mean_list.append(np.mean(loss_list))\n",
    "    taget_index = np.argmin(loss_mean_list)\n",
    "    model_i = taget_index // len(steps_list)\n",
    "    split_step = steps_list[taget_index % len(steps_list)]\n",
    "    return model_i, split_step\n",
    "# learning perturbation over the ensemble of models\n",
    "# 在多个模型集合上进行扰动优化\n",
    "# 多次实验\n",
    "# total_iterations = args.epochs * len(train_dataloader)\n",
    "# model_state_num = steps_list*len(num_models)\n",
    "assert args.model_select_mode in ['order','min_loss']\n",
    "print(f\"avalaible model num: {num_models},available steps: {str(steps_list)},total train step :{str(args.total_train_steps)}\")\n",
    "# raise ValueError(\"The number of classes must be greater than 1.\")\n",
    "# 如果是平均顺序选择模型池中的模型\n",
    "if args.model_select_mode == 'order':\n",
    "    for _ in range(args.total_trail_num):          \n",
    "        # 针对每一个模型\n",
    "        for model_i in range(num_models):\n",
    "            print(f'using model {model_i}')\n",
    "            # 确定关键组件\n",
    "            start_time = time.time()\n",
    "            text_encoder, unet, tokenizer, noise_scheduler, vae = MODEL_BANKS[model_i]\n",
    "            # 对于每一个中间状态step\n",
    "            for split_step in steps_list: \n",
    "                # 加载unet和文本编码器的中间状态参数\n",
    "                unet.load_state_dict(init_model_state_pool[model_i][split_step][\"unet\"])\n",
    "                text_encoder.load_state_dict(init_model_state_pool[model_i][split_step][\"text_encoder\"])\n",
    "                f = [unet, text_encoder]\n",
    "                # f = [unet.to(device_1), text_encoder.to(device_1)]\n",
    "                \n",
    "                # 每advance_steps步进行一次防御优化/对于每一组模型参数，进行200/2=100次对抗训练\n",
    "                print(f'start {args.interval // args.advance_steps} times of defense optimization in step-{split_step} model')\n",
    "                for j in range(args.interval // args.advance_steps):\n",
    "                    # 更新一次扰动，使得扰动更加强大,后续需要在此处引入随机性（多轮采样优化），并以扰动的平均值作为后续的扰动\n",
    "                    # vkeilo add it\n",
    "                    mean_delta = perturbed_data.clone().detach()\n",
    "                    print(f'start {args.sampling_times_delta} times of delta sampling ')\n",
    "                    for k in range(args.sampling_times_delta):\n",
    "                        print(f'sample delta {k}/{args.sampling_times_delta} times')\n",
    "                        if args.attack_mode == \"pgd\":\n",
    "                            perturbed_data,rubust_loss = defender.perturb(f, perturbed_data, original_data, vae, tokenizer, noise_scheduler,)\n",
    "                        elif args.attack_mode == \"pan\":\n",
    "                            perturbed_data,rubust_loss = attacker.attack(f, perturbed_data, original_data, vae, tokenizer, noise_scheduler,)\n",
    "                        # wandb.log({\"perturbedloss\": rubust_loss})\n",
    "                        # 此处引入随机梯度朗之万动力学\n",
    "                        if args.SGLD_method == 'allSGLD' or args.SGLD_method == 'deltaSGLD':\n",
    "                            perturbed_data = utils.SGLD(perturbed_data, args.sampling_step_delta, delta_noise_epsion).detach()\n",
    "                        mean_delta = args.beta_s * mean_delta + (1 - args.beta_s) * perturbed_data\n",
    "                    mean_delta.detach()\n",
    "                    perturbed_data = mean_delta\n",
    "                    print(f\"max pixel change:{find_max_pixel_change(perturbed_data, original_data)}\")\n",
    "                    # f[0] = f[0].to(device_0)\n",
    "                    # f[1] = f[1].to(device_0)\n",
    "                    # perturbed_data = defender.perturb(f, perturbed_data, original_data, vae, tokenizer, noise_scheduler)\n",
    "                    \n",
    "                    # 扰动优化次数更新 +1\n",
    "                    cnt+=1\n",
    "                    # 在新的扰动数据下，训练advance_steps步，后续需要在此处引入随机性（多轮采样优化参数），并以参数的平均值作为模型的参数\n",
    "                    back_parameters_list = [f[0].state_dict(),\n",
    "                                            f[1].state_dict()]\n",
    "\n",
    "                    mean_theta_list = [f[0].state_dict(),\n",
    "                                    f[1].state_dict()]\n",
    "                    \n",
    "                    # print(f'start {args.sampling_times_theta} times of theta sampling')\n",
    "                    for k in range(args.sampling_times_theta):\n",
    "                        print(f'sample theta {k}/{args.sampling_times_theta} times')\n",
    "                        f = train_few_step(\n",
    "                            args,\n",
    "                            f,\n",
    "                            tokenizer,\n",
    "                            noise_scheduler,\n",
    "                            vae,\n",
    "                            perturbed_data.float(),\n",
    "                            args.advance_steps,\n",
    "                            # device = device_1\n",
    "                            dpcopy = False,\n",
    "                            task_loss_name='model_theta_loss',\n",
    "                        )\n",
    "                        torch.cuda.empty_cache()\n",
    "                        for model_index, model in enumerate(f):\n",
    "                            # print(f\"\\nbefore culcu, GPU: {gpu.name}, Free Memory: {gpu.memoryFree / 1024:.2f} GB\")\n",
    "                            for name, p in model.named_parameters():\n",
    "                                # 先尝试固定学习率的（因为迭代次数暂未确定）\n",
    "                                # lr_now = lr_scheduler.get_last_lr()[0]\n",
    "                                # 参数采样,引入随机性\n",
    "                                if args.SGLD_method == 'allSGLD' or args.SGLD_method == 'thetaSGLD':\n",
    "                                    p.data = utils.SGLD(p.data, args.sampling_step_theta, theta_noise_epsion)\n",
    "                                # 模型参数也使用指数平均\n",
    "                                # mean_theta_list[model_index][name] = args.beta_s * mean_theta_list[model_index][name] + (1 - args.beta_s) * p.data.to('cpu')\n",
    "                                # mean_theta_list[model_index][name] = args.beta_s * mean_theta_list[model_index][name] + (1 - args.beta_s) * p.data\n",
    "                                mean_theta_list[model_index][name].mul_(args.beta_s).add_((1 - args.beta_s) * p.data)\n",
    "                            # print(f\"\\nafter calcu params, GPU: {gpu.name}, Free Memory: {gpu.memoryFree / 1024:.2f} GB\")\n",
    "                            # torch.cuda.empty_cache()\n",
    "                    # lr_scheduler.step()\n",
    "                    # 对于模型的unet和文本编码器，分别更新参数\n",
    "                    for back_parameters, mean_theta in zip(back_parameters_list,mean_theta_list):\n",
    "                        for name in back_parameters:\n",
    "                            back_parameters[name] = args.beta_p * back_parameters[name] + (1 - args.beta_p) * mean_theta[name]\n",
    "                            # back_parameters[name] = back_parameters[name].float()\n",
    "                            # back_parameters[name].mul_(args.beta_p).add_((1 - args.beta_p) * mean_theta[name])\n",
    "                    for index, model in enumerate(f):\n",
    "                        # model.load_state_dict({k: v.to(device_g) for k, v in back_parameters_list[index].items()})\n",
    "                        model.load_state_dict(back_parameters_list[index])\n",
    "                        pass\n",
    "                    del back_parameters_list\n",
    "                    del mean_theta_list\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    # f = train_few_step(\n",
    "                    #     args,\n",
    "                    #     f,\n",
    "                    #     tokenizer,\n",
    "                    #     noise_scheduler,\n",
    "                    #     vae,\n",
    "                    #     perturbed_data.float(),\n",
    "                    #     args.advance_steps,\n",
    "                    # )\n",
    "                    pbar.update(1)\n",
    "                    # 每1000次扰动优化，保存一次扰动示例图像\n",
    "                    if cnt % 1000 == 0:\n",
    "                        save_image(perturbed_data, f\"{cnt}\")\n",
    "                # frequently release the memory due to limited GPU memory, \n",
    "                # env with more gpu might consider to remove the following lines for boosting speed\n",
    "                # 释放资源\n",
    "                del f \n",
    "                torch.cuda.empty_cache()\n",
    "            end_time = time.time()\n",
    "            # logger.info(f\"model {model_i} adversarial training Time cost: {(end_time - start_time) / 60} min\")\n",
    "            # wandb.log({f\"Time cost of model {model_i} adversarial training\": (end_time - start_time) / 60})\n",
    "            del unet, text_encoder, tokenizer, noise_scheduler, vae\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache() \n",
    "\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()      \n",
    "\n",
    "pbar.close()\n",
    "# 保存最后的结果\n",
    "# save_image(perturbed_data, \"final\")\n",
    "\n",
    "print(f\"max pixel change:{find_max_pixel_change(perturbed_data, original_data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m init_model_state_pool\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/core/displayhook.py:268\u001b[0m, in \u001b[0;36mDisplayHook.__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_displayhook()\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_output_prompt()\n\u001b[0;32m--> 268\u001b[0m format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_format_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_user_ns(result)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_exec_result(result)\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/core/displayhook.py:157\u001b[0m, in \u001b[0;36mDisplayHook.compute_format_data\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_format_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, result):\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute format data of the object to be displayed.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    The format data is a generalization of the :func:`repr` of an object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/core/formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    177\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/core/formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/core/formatters.py:708\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    701\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[1;32m    702\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[1;32m    704\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[1;32m    705\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[1;32m    706\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[1;32m    707\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 708\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:393\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _get_mro(obj_class):\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_pprinters:\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;66;03m# printer registered in self.type_pprinters\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_pprinters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m         \u001b[38;5;66;03m# deferred printer\u001b[39;00m\n\u001b[1;32m    396\u001b[0m         printer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_deferred_types(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:692\u001b[0m, in \u001b[0;36m_dict_pprinter_factory.<locals>.inner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    690\u001b[0m     p\u001b[38;5;241m.\u001b[39mpretty(key)\n\u001b[1;32m    691\u001b[0m     p\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 692\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m p\u001b[38;5;241m.\u001b[39mend_group(step, end)\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:393\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _get_mro(obj_class):\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_pprinters:\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;66;03m# printer registered in self.type_pprinters\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_pprinters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m         \u001b[38;5;66;03m# deferred printer\u001b[39;00m\n\u001b[1;32m    396\u001b[0m         printer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_deferred_types(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:692\u001b[0m, in \u001b[0;36m_dict_pprinter_factory.<locals>.inner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    690\u001b[0m     p\u001b[38;5;241m.\u001b[39mpretty(key)\n\u001b[1;32m    691\u001b[0m     p\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 692\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m p\u001b[38;5;241m.\u001b[39mend_group(step, end)\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:393\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _get_mro(obj_class):\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_pprinters:\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;66;03m# printer registered in self.type_pprinters\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_pprinters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m         \u001b[38;5;66;03m# deferred printer\u001b[39;00m\n\u001b[1;32m    396\u001b[0m         printer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_deferred_types(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:692\u001b[0m, in \u001b[0;36m_dict_pprinter_factory.<locals>.inner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    690\u001b[0m     p\u001b[38;5;241m.\u001b[39mpretty(key)\n\u001b[1;32m    691\u001b[0m     p\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 692\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m p\u001b[38;5;241m.\u001b[39mend_group(step, end)\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:393\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _get_mro(obj_class):\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_pprinters:\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;66;03m# printer registered in self.type_pprinters\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_pprinters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m         \u001b[38;5;66;03m# deferred printer\u001b[39;00m\n\u001b[1;32m    396\u001b[0m         printer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_deferred_types(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:903\u001b[0m, in \u001b[0;36m_ordereddict_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    901\u001b[0m     p\u001b[38;5;241m.\u001b[39mpretty(cls_ctor(RawText(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj):\n\u001b[0;32m--> 903\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_ctor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    905\u001b[0m     p\u001b[38;5;241m.\u001b[39mpretty(cls_ctor())\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:407\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    405\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_repr_pretty_\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(meth):\n\u001b[0;32m--> 407\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \\\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _repr_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:564\u001b[0m, in \u001b[0;36mCallExpression._repr_pretty_\u001b[0;34m(self, p, cycle)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs:\n\u001b[1;32m    563\u001b[0m     new_item()\n\u001b[0;32m--> 564\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg_name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    566\u001b[0m     new_item()\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:393\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _get_mro(obj_class):\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_pprinters:\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;66;03m# printer registered in self.type_pprinters\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_pprinters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m         \u001b[38;5;66;03m# deferred printer\u001b[39;00m\n\u001b[1;32m    396\u001b[0m         printer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_deferred_types(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:640\u001b[0m, in \u001b[0;36m_seq_pprinter_factory.<locals>.inner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    638\u001b[0m         p\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    639\u001b[0m         p\u001b[38;5;241m.\u001b[39mbreakable()\n\u001b[0;32m--> 640\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# Special case for 1-item tuples.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     p\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:393\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _get_mro(obj_class):\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_pprinters:\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;66;03m# printer registered in self.type_pprinters\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_pprinters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m         \u001b[38;5;66;03m# deferred printer\u001b[39;00m\n\u001b[1;32m    396\u001b[0m         printer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_deferred_types(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:640\u001b[0m, in \u001b[0;36m_seq_pprinter_factory.<locals>.inner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    638\u001b[0m         p\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    639\u001b[0m         p\u001b[38;5;241m.\u001b[39mbreakable()\n\u001b[0;32m--> 640\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# Special case for 1-item tuples.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     p\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    408\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \\\n\u001b[1;32m    409\u001b[0m                         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 410\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/IPython/lib/pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/torch/_tensor.py:427\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    424\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    425\u001b[0m     )\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/torch/_tensor_str.py:637\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    636\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/torch/_tensor_str.py:568\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    566\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    567\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 568\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    571\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/apps/miniconda/envs/Metacloak/lib/python3.9/site-packages/torch/_tensor_str.py:310\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_neg()\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfloat16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbfloat16:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcomplex32:\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfloat()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init_model_state_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "meta poison with model ensemble:   0%|          | 0/6 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:adv_image.grad.sign(): tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')\n",
      "epoch: 0, loss_S: -0.1752, loss_D: -0.0488\n",
      "D:adv_image.grad.sign(): tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')\n",
      "epoch: 1, loss_S: -0.1268, loss_D: -0.0776\n",
      "D:adv_image.grad.sign(): tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')\n",
      "epoch: 2, loss_S: -0.0479, loss_D: -0.0523\n",
      "D:adv_image.grad.sign(): tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')\n",
      "epoch: 3, loss_S: -0.0534, loss_D: -0.0485\n",
      "D:adv_image.grad.sign(): tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')\n",
      "epoch: 4, loss_S: -0.0975, loss_D: -0.0312\n",
      "D:adv_image.grad.sign(): tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')\n",
      "epoch: 5, loss_S: -0.1354, loss_D: -0.1050\n",
      "tensor([0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0.])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_few_step() got an unexpected keyword argument 'copy_flag'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# break\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# perturbed_data,rubust_loss = defender.perturb(f, perturbed_data, original_data, vae, tokenizer, noise_scheduler,)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 扰动优化次数更新 +1\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# wandb.log({\"defender_rubust_loss_without_MAT\": rubust_loss})\u001b[39;00m\n\u001b[1;32m     31\u001b[0m cnt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 33\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_few_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoise_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvae\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperturbed_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy_flag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# 每1000次扰动优化，保存一次扰动示例图像\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: train_few_step() got an unexpected keyword argument 'copy_flag'"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "# 提取保存的中间状态的step数据（0,199，399...）        \n",
    "steps_list = list(init_model_state_pool[0].keys())\n",
    "# 进度条，总train_few_step调用的次数\n",
    "pbar = tqdm(total=args.total_trail_num * num_models * (args.interval // args.advance_steps) * len(steps_list), desc=\"meta poison with model ensemble\")\n",
    "cnt=0\n",
    "# learning perturbation over the ensemble of models\n",
    "# 在多个模型集合上进行扰动优化\n",
    "# 多次实验\n",
    "for _ in range(args.total_trail_num):\n",
    "    # 针对每一个模型\n",
    "    for model_i in range(num_models):\n",
    "        # 确定关键组件\n",
    "        text_encoder, unet, tokenizer, noise_scheduler, vae = MODEL_BANKS[model_i]\n",
    "        # 对于每一个中间状态step\n",
    "        for split_step in steps_list: \n",
    "            # 加载unet和文本编码器的中间状态参数\n",
    "            unet.load_state_dict(init_model_state_pool[model_i][split_step][\"unet\"])\n",
    "            text_encoder.load_state_dict(init_model_state_pool[model_i][split_step][\"text_encoder\"])\n",
    "            f = [unet, text_encoder]\n",
    "            # 每advance_steps步进行一次防御优化\n",
    "            for j in range(args.interval // args.advance_steps):\n",
    "                before = deepcopy(perturbed_data)\n",
    "                perturbed_data,rubust_loss = attacker.attack(f, perturbed_data, original_data, vae, tokenizer, noise_scheduler)\n",
    "                print(attacker.get_Linfty_norm(perturbed_data.to('cpu')-before.to('cpu')))\n",
    "                print(attacker.get_Linfty_norm(perturbed_data.to('cpu')-original_data))\n",
    "                # break\n",
    "                # perturbed_data,rubust_loss = defender.perturb(f, perturbed_data, original_data, vae, tokenizer, noise_scheduler,)\n",
    "                # 扰动优化次数更新 +1\n",
    "                # wandb.log({\"defender_rubust_loss_without_MAT\": rubust_loss})\n",
    "                cnt+=1\n",
    "                \n",
    "                f = train_few_step(\n",
    "                    args,\n",
    "                    f,\n",
    "                    tokenizer,\n",
    "                    noise_scheduler,\n",
    "                    vae,\n",
    "                    perturbed_data.float(),\n",
    "                    args.advance_steps,\n",
    "                    copy_flag = False,\n",
    "                )\n",
    "                pbar.update(1)\n",
    "                # 每1000次扰动优化，保存一次扰动示例图像\n",
    "                if cnt % 1000 == 0:\n",
    "                    save_image(perturbed_data, f\"{cnt}\")\n",
    "            \n",
    "            # frequently release the memory due to limited GPU memory, \n",
    "            # env with more gpu might consider to remove the following lines for boosting speed\n",
    "            # 释放资源\n",
    "            del f \n",
    "            torch.cuda.empty_cache()\n",
    "            # break\n",
    "            \n",
    "        del unet, text_encoder, tokenizer, noise_scheduler, vae\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache() \n",
    "        # break\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()   \n",
    "    # break   \n",
    "pbar.close()\n",
    "# 保存最后的结果\n",
    "save_image(perturbed_data, \"final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Metacloak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
