{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在SD21上测试PAN攻击"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import wandb\n",
    "import argparse\n",
    "import copy\n",
    "import hashlib\n",
    "import itertools\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import datasets\n",
    "import diffusers\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed\n",
    "from diffusers import AutoencoderKL, DDPMScheduler, DiffusionPipeline, UNet2DConditionModel\n",
    "from diffusers.utils.import_utils import is_xformers_available\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, PretrainedConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 首先是模型加载和训练代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_few_step(\n",
    "    args,\n",
    "    models,\n",
    "    tokenizer,\n",
    "    noise_scheduler,\n",
    "    vae,\n",
    "    data_tensor: torch.Tensor,\n",
    "    num_steps=20,\n",
    "    step_wise_save=False,\n",
    "    save_step=100, \n",
    "    retain_graph=False,\n",
    "    task_loss_name = None,\n",
    "):\n",
    "    # Load the tokenizer\n",
    "\n",
    "    unet, text_encoder = copy.deepcopy(models[0]), copy.deepcopy(models[1])\n",
    "    # 绑定unet和文本编码器的参数，共同优化\n",
    "    params_to_optimize = itertools.chain(unet.parameters(), text_encoder.parameters())\n",
    "\n",
    "    # 设置优化器，优化目标为unet参数和文本编码器参数\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        params_to_optimize,\n",
    "        lr=args.learning_rate,\n",
    "        betas=(0.9, 0.999),\n",
    "        weight_decay=1e-2,\n",
    "        eps=1e-08,\n",
    "    )\n",
    "\n",
    "    train_dataset = DreamBoothDatasetFromTensor(\n",
    "        data_tensor,\n",
    "        # A photo of sks person\n",
    "        args.instance_prompt,\n",
    "        tokenizer,\n",
    "        args.class_data_dir,\n",
    "        args.class_prompt,\n",
    "        args.resolution,\n",
    "        args.center_crop,\n",
    "    )\n",
    "\n",
    "    weight_dtype = torch.bfloat16\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    # 将关键模型移动到对应设备\n",
    "    vae.to(device, dtype=weight_dtype)\n",
    "    text_encoder.to(device, dtype=weight_dtype)\n",
    "    unet.to(device, dtype=weight_dtype)\n",
    "\n",
    "    \n",
    "    step2modelstate={}\n",
    "        \n",
    "    pbar = tqdm(total=num_steps, desc=\"training\")\n",
    "    for step in range(num_steps):\n",
    "        # 根据设置选择是否保存训练中间过程参数\n",
    "        if step_wise_save and ((step+1) % save_step == 0 or step == 0):\n",
    "            # make sure the model state dict is put to cpu\n",
    "            step2modelstate[step] = {\n",
    "                \"unet\": copy.deepcopy(unet.cpu().state_dict()),\n",
    "                \"text_encoder\": copy.deepcopy(text_encoder.cpu().state_dict()),\n",
    "            }\n",
    "            # move the model back to gpu\n",
    "            unet.to(device, dtype=weight_dtype); text_encoder.to(device, dtype=weight_dtype)\n",
    "            \n",
    "        pbar.update(1)\n",
    "        # 训练模式\n",
    "        unet.train()\n",
    "        text_encoder.train()\n",
    "        # 循环从训练数据集中取一个样本\n",
    "        step_data = train_dataset[step % len(train_dataset)]\n",
    "        # 将样本中的类别图片和实例图片整合并移动到设备上\n",
    "        pixel_values = torch.stack([step_data[\"instance_images\"], step_data[\"class_images\"]]).to(\n",
    "            device, dtype=weight_dtype\n",
    "        )\n",
    "        # 将样本中的类别提示词和实例提示词整合并移动到设备上\n",
    "        input_ids = torch.cat([step_data[\"instance_prompt_ids\"], step_data[\"class_prompt_ids\"]], dim=0).to(device)\n",
    "        # 使用VAE对图像进行编码，并对潜在表示进行后处理\n",
    "        latents = vae.encode(pixel_values).latent_dist.sample()\n",
    "        latents = latents * vae.config.scaling_factor\n",
    "\n",
    "        # Sample noise that we'll add to the latents\n",
    "        # 向图片编码向量（潜在空间向量表示）添加随机噪声\n",
    "        noise = torch.randn_like(latents)\n",
    "        # batch_size\n",
    "        bsz = latents.shape[0]\n",
    "        # Sample a random timestep for each image\n",
    "        # 为每个图片生成一个随机step\n",
    "        timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device)\n",
    "        timesteps = timesteps.long()\n",
    "\n",
    "        # Add noise to the latents according to the noise magnitude at each timestep\n",
    "        # (this is the forward diffusion process)\n",
    "        # 前向过程，得到前向扩散特定时间步后的图片的潜在空间向量\n",
    "        noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "\n",
    "        # Get the text embedding for conditioning\n",
    "        # 文本编码向量作为条件信息\n",
    "        encoder_hidden_states = text_encoder(input_ids)[0]\n",
    "        \n",
    "        # Predict the noise residual\n",
    "        # 模型基于当前的噪声潜在表示（noisy_latents）、时间步（timesteps）和文本条件（encoder_hidden_states），预测噪声残差\n",
    "        model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
    "\n",
    "        # Get the target for loss depending on the prediction type\n",
    "        # 预测的可以是噪声，也可以是变化速度\n",
    "        if noise_scheduler.config.prediction_type == \"epsilon\":\n",
    "            target = noise\n",
    "        elif noise_scheduler.config.prediction_type == \"v_prediction\":\n",
    "            target = noise_scheduler.get_velocity(latents, noise, timesteps)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown prediction type {noise_scheduler.config.prediction_type}\")\n",
    "\n",
    "        # with prior preservation loss\n",
    "        # 可选是否使用先验保留损失\n",
    "        if args.with_prior_preservation:\n",
    "            # 再次分为一半一半，对应之前的stack操作\n",
    "            model_pred, model_pred_prior = torch.chunk(model_pred, 2, dim=0)\n",
    "            target, target_prior = torch.chunk(target, 2, dim=0)\n",
    "\n",
    "            # Compute instance loss\n",
    "            instance_loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\")\n",
    "\n",
    "            # Compute prior loss  确保在原来类别上的生成能力不丢失\n",
    "            prior_loss = F.mse_loss(model_pred_prior.float(), target_prior.float(), reduction=\"mean\")\n",
    "\n",
    "            # Add the prior loss to the instance loss.\n",
    "            loss = instance_loss + args.prior_loss_weight * prior_loss\n",
    "\n",
    "        else:\n",
    "            # 不使用先验保留损失\n",
    "            loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\")\n",
    "        if task_loss_name is not None:\n",
    "            wandb.log({f\"{task_loss_name}\": loss.item()})\n",
    "        # 反向传播\n",
    "        loss.backward(retain_graph=retain_graph)\n",
    "        # 梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(params_to_optimize, 1.0, error_if_nonfinite=True)\n",
    "        # 参数优化\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    pbar.close()\n",
    "    # 返回训练的参数数据\n",
    "    if step_wise_save:\n",
    "        return [unet, text_encoder], step2modelstate\n",
    "    else:     \n",
    "        return [unet, text_encoder]\n",
    "\n",
    "# 主要模型的加载\n",
    "def load_model(args, model_path):\n",
    "    print(model_path)\n",
    "    # import correct text encoder class\n",
    "    text_encoder_cls = import_model_class_from_model_name_or_path(model_path, args.revision)\n",
    "\n",
    "    # Load scheduler and models\n",
    "    # 文本编码器加载\n",
    "    text_encoder = text_encoder_cls.from_pretrained(\n",
    "        model_path,\n",
    "        subfolder=\"text_encoder\",\n",
    "        revision=args.revision,\n",
    "    )\n",
    "    # unet加载\n",
    "    unet = UNet2DConditionModel.from_pretrained(model_path, subfolder=\"unet\", revision=args.revision)\n",
    "    # tokenizer加载\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_path,\n",
    "        subfolder=\"tokenizer\",\n",
    "        revision=args.revision,\n",
    "        use_fast=False,\n",
    "    )\n",
    "    # 使用DDPM同款调度器\n",
    "    noise_scheduler = DDPMScheduler.from_pretrained(model_path, subfolder=\"scheduler\")\n",
    "    # 加载预训练的vae，vae不需要更新参数\n",
    "    vae = AutoencoderKL.from_pretrained(model_path, subfolder=\"vae\", revision=args.revision)\n",
    "\n",
    "    vae.requires_grad_(False)\n",
    "\n",
    "    # 甚至可以不更新文本编码器的参数\n",
    "    if not args.train_text_encoder:\n",
    "        text_encoder.requires_grad_(False)\n",
    "\n",
    "    if args.enable_xformers_memory_efficient_attention:\n",
    "        print(\"You selected to used efficient xformers\")\n",
    "        print(\"Make sure to install the following packages before continue\")\n",
    "        print(\"pip install triton==2.0.0.dev20221031\")\n",
    "        print(\"pip install pip install xformers==0.0.17.dev461\")\n",
    "\n",
    "        unet.enable_xformers_memory_efficient_attention()\n",
    "    # 返回5个关键模型\n",
    "    return text_encoder, unet, tokenizer, noise_scheduler, vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scheduler = DDPMScheduler.from_pretrained('/data/home/yekai/github/mypro/MetaCloak/SD/stable-diffusion-2-1-base', subfolder=\"scheduler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diffusers.schedulers.scheduling_ddpm.DDPMScheduler"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DDPMScheduler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Metacloak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
